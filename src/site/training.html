<!DOCTYPE HTML>
<html>
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Inference - Aika</title>
	<link rel="stylesheet" href="css/style.css" type="text/css">
	<link rel="shortcut icon" href="images/favicon.png" />

	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
					(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
				m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-77552310-1', 'auto');
		ga('send', 'pageview');

	</script>
	<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
	<script type="text/javascript" async
			src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
	</script>
</head>
<body>
<div id="header">
	<div>
		<div class="logo">
			<a rel="canonical" href="https://aika.network"></a>
		</div>
		<ul id="navigation">
			<li>
				<a rel="canonical" href="https://aika.network">Overall idea</a>
			</li>
			<li>
				<a rel="canonical" href="blog.html">Blog</a>
			</li>
			<li class="active">
				<a rel="canonical" href="inference.html">Inference</a>
			</li>
			<li>
				<a rel="canonical" href="training.html">Training</a>
			</li>
			<li>
				<a rel="canonical" href="usage.html">Examples</a>
			</li>
			<li>
				<a rel="canonical" href="resources.html">Resources</a>
			</li>
            <li>
                <a rel="canonical" href="https://github.com/aika-algorithm/aika">GitHub</a>
            </li>
		</ul>
	</div>
</div>
	<div id="contents">
		<div align="right"><span style='color: #FF0000;'>October 09, 2020</span></div>
		<div align="middle"><b><span style='color: #FF0000;'>Draft</span></b></div>
		<div class="features">
			<h1>How the network is trained</h1>
			<p>
			<h2>The entropy framework</h2>
			<p>
				Obviously, since the network contains a lot of cycles, the usual backpropagation algorithm won't work very well for this type of network. Also relying on handcrafted labels that are applied to the output of the network seems very error-prone and it creates a large distance between our training signal and the weights that we would like to adjust. Hence we would like to train our pattern more locally without the reliance on an external signal source. This is where Shannon entropy comes in quite handy. If we consider the word example again, we can measure the information content of each letter by calculating the Shannon entropy. We can look at the word pattern neuron as a way of compressing the information given by the individual letter neurons. This compression can be formalized using the mutual information which can then be used to derive an objective function for our training algorithm. The resulting derivative function exhibits a very interesting and unexpected behavior with regard to when the synapse weights and bias values are increased or decreased.

				When feeding a text or an image into a neural network there is a lot of hidden structure buried in the data that can
				only insufficiently be captured by manually created labels. These structures consist of coinciding features within the data.
				Now, if we use a single neuron to encode the information of such a cluster of features we would need much less information
				to encode the same message that was given in the input data. In order to quantify these information we can utilize the
				framework provided by the shannon entry. In other words, we can think of the neural network as a compression algorithm
				that constantly tries to optimize its own compression rate.

				$$I(X;Y) = \sum_{y \in \mathcal Y} \sum_{x \in \mathcal X}
				{ p_{(X,Y)}(x, y) \log{ \left(\frac{p_{(X,Y)}(x, y)}{p_X(x)\,p_Y(y)} \right) }} $$
			</p>
			<h2>Counting Frequencies</h2>
			<p>
				Since the calculation of the entropy relies on probability distributions, we need to figure how these are determined.
				This part may sound easier than it actually is, since there are some pitfalls to consider. A simple way to estimate
				the probability for a neuron would look like this:

				$$P(neuron) = \frac{\text{number of fired activations}}{\text{size of the sample space}}$$

				Counting the number of fired activations for a neuron is easy but how do we determine the sample space and is the sample
				space equal for all the neurons? The answer to that question is no. The size of the sample space depends on the space that the
				activations cover in the input data set. For example an activation representing a single letter requires less space than
				an activation representing a whole word. In the case of a neuron representing a single letter we could determine the
				size of the sample space $N$ by summing up the number of characters of all the training documents. For neurons whose activations
				cover a larger space within the document we need to divide the the total number of characters by the average
				covered area of this neurons activations.

				First the frequencies are counted by summing up the input activations


				$$f(X_i, Y) = \sum\limits_{d=0}^N{Y_d \cdot X_{di}}$$

				The probability distributions are then calculated by dividing the frequency through the number of trainings instances.

				$$P(Y) = \dfrac{f(Y)}{N}$$

				$$P(X_i,Y) = \dfrac{f(X_i,Y)}{N}$$

				However, there are two problems with this simple form of frequency counting. The first one is that the
				sample might be too small to be reliable. In this case the dirichlet distribution might help to estimate
				how reliable the distribution is, but things are getting complicated here pretty quickly. The second problem
				is, that the distribution is a moving target. Since we constantly adjust the weights of the excitatory neuron,
				this of course also means that the probability distributions are changing as well. This problem
				can be tackled by using a moving average to calculate the probabilities.
			</p>
			<h2>The Beta-Distribution</h2>
			<p>
				Then there is the problem that right after a new neuron is introduced there are very few training instances for this statistic yet we still want to adjust the weights of this neuron. Hence we need a conservative estimate of what we already know for certain about the probabilities. Since entropy is based on the surprisal (-log(p)) which gets large when the probability gets close to zero, we can use the cumulative beta distribution to determine what the maximum probability is that can be explained by the observed frequencies.
			</p>
			<h2>The optimization Problem</h2>
			<p>
				Since we would like to optimize the compression rate within the network, we need to find a way to adjust the synapse weights and the neuron
				biases such that the network requires less information to encode the message of the input data.
			</p>
			<h2>Concept Drift</h2>
			<p>
				Another problem is that of concept drift. Since we are using the distribution to adjust the synapse weights this will lead to changes in the activation patterns and therefore to changes in the distributions again.

				$$G = \sum  \limits _{ikl}{P(x_{ik},y_{l}) \cdot log \Big( \frac{P(x_{ik},y_{l})}{P(x_{ik}) \cdot P(y_{l})} \Big)}$$

			</p>
        </div>
	</div>
</body>
</html>